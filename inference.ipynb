{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1a4b2a",
   "metadata": {
    "papermill": {
     "duration": 0.005573,
     "end_time": "2023-10-28T18:13:22.361380",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.355807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trading at the Close - Inference\n",
    "-----------------------\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dc06f",
   "metadata": {
    "papermill": {
     "duration": 0.004557,
     "end_time": "2023-10-28T18:13:22.372966",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.368409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67134ff",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.385731Z",
     "iopub.status.busy": "2023-10-28T18:13:22.384649Z",
     "iopub.status.idle": "2023-10-28T18:13:22.807773Z",
     "shell.execute_reply": "2023-10-28T18:13:22.806571Z"
    },
    "papermill": {
     "duration": 0.432428,
     "end_time": "2023-10-28T18:13:22.810745",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.378317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133b1472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.822670Z",
     "iopub.status.busy": "2023-10-28T18:13:22.822156Z",
     "iopub.status.idle": "2023-10-28T18:13:22.828972Z",
     "shell.execute_reply": "2023-10-28T18:13:22.827867Z"
    },
    "papermill": {
     "duration": 0.016915,
     "end_time": "2023-10-28T18:13:22.832751",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.815836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/optiver-inference-utils', '/kaggle/working', '/kaggle/lib/kagglegym', '/kaggle/lib', '/kaggle/input/optiver-trading-at-the-close', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/root/.local/lib/python3.10/site-packages', '/opt/conda/lib/python3.10/site-packages', '/root/src/BigQuery_Helper']\n"
     ]
    }
   ],
   "source": [
    "utils_path = Path(\"/\", \"kaggle\", \"input\", \"optiver-inference-utils\")\n",
    "if str(utils_path) not in sys.path:\n",
    "    sys.path = [str(utils_path),] + sys.path\n",
    "    \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f83984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.844917Z",
     "iopub.status.busy": "2023-10-28T18:13:22.844192Z",
     "iopub.status.idle": "2023-10-28T18:13:22.850062Z",
     "shell.execute_reply": "2023-10-28T18:13:22.849323Z"
    },
    "papermill": {
     "duration": 0.014577,
     "end_time": "2023-10-28T18:13:22.852310",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.837733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LOCAL = True\n",
    "    JOBS_PATH = Path(\"/\", \"kaggle\", \"input\", \"optiver-trained-artifacts\", \"job_artifacts\")\n",
    "    FEATURES_PATH = JOBS_PATH.joinpath(\"optiver-feature_selection-0008\")\n",
    "    FEATURES_NAME = \"feature_names.json\"\n",
    "    MEMORY_HORIZON = 5 # Retain MEMORY_HORIZON date_ids\n",
    "    MODEL_PATH = JOBS_PATH.joinpath(\"optiver-tuning_lgbmregressor-0009\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bed59",
   "metadata": {
    "papermill": {
     "duration": 0.004574,
     "end_time": "2023-10-28T18:13:22.861928",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.857354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a1a3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.874061Z",
     "iopub.status.busy": "2023-10-28T18:13:22.873272Z",
     "iopub.status.idle": "2023-10-28T18:13:22.879345Z",
     "shell.execute_reply": "2023-10-28T18:13:22.878450Z"
    },
    "papermill": {
     "duration": 0.014838,
     "end_time": "2023-10-28T18:13:22.881714",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.866876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86dd58ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.893358Z",
     "iopub.status.busy": "2023-10-28T18:13:22.892981Z",
     "iopub.status.idle": "2023-10-28T18:13:22.921380Z",
     "shell.execute_reply": "2023-10-28T18:13:22.920324Z"
    },
    "papermill": {
     "duration": 0.037372,
     "end_time": "2023-10-28T18:13:22.924120",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.886748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "optiver2023.make_env.func_dict['__called__'] = False\n",
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fd3911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.935883Z",
     "iopub.status.busy": "2023-10-28T18:13:22.935500Z",
     "iopub.status.idle": "2023-10-28T18:13:22.943303Z",
     "shell.execute_reply": "2023-10-28T18:13:22.942494Z"
    },
    "papermill": {
     "duration": 0.016216,
     "end_time": "2023-10-28T18:13:22.945424",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.929208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_df(df1, df2, on):\n",
    "\n",
    "    if len(df1) == 0:\n",
    "        return df2\n",
    "    elif len(df2) == 0:\n",
    "        return df1\n",
    "    else:\n",
    "        df3=pd.merge(df1, df2, on=on, how='outer')\n",
    "        #now we have a mess to fix\n",
    "        cols=[x[:-2] for x in df3.columns if x.endswith('_x')]\n",
    "        for i_col in cols:\n",
    "            df3.loc[:,i_col+'_x']=df3[i_col+'_x'].combine_first(df3[i_col+'_y'])\n",
    "            df3.rename(columns={i_col+'_x':i_col},inplace=True)\n",
    "            df3.drop(columns=[i_col+'_y'],inplace=True)\n",
    "        return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b0aa88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.957437Z",
     "iopub.status.busy": "2023-10-28T18:13:22.956673Z",
     "iopub.status.idle": "2023-10-28T18:13:22.964526Z",
     "shell.execute_reply": "2023-10-28T18:13:22.963306Z"
    },
    "papermill": {
     "duration": 0.016356,
     "end_time": "2023-10-28T18:13:22.966842",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.950486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_aggregations(df: pd.DataFrame, aggregations_date = None, reduce_memory: bool = False):\n",
    "\n",
    "    # Perform aggregations and features dependent on these\n",
    "    if aggregations_date is not None:\n",
    "        for key, value in aggregations_date.items():\n",
    "            aggr_index = [\"date_id\", \"seconds_in_bucket\"]\n",
    "            aggr_colum = pd.Series(value, name=key + \"_date_aggr\")\n",
    "            aggr_colum.index = aggr_colum.index.set_names(aggr_index)\n",
    "            df = merge_df(df, aggr_colum, on=aggr_index)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08541795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.978910Z",
     "iopub.status.busy": "2023-10-28T18:13:22.978150Z",
     "iopub.status.idle": "2023-10-28T18:13:22.983649Z",
     "shell.execute_reply": "2023-10-28T18:13:22.982876Z"
    },
    "papermill": {
     "duration": 0.014277,
     "end_time": "2023-10-28T18:13:22.986053",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.971776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    model_type,\n",
    "    booster_file\n",
    "):\n",
    "    model = model_type(model_file=str(booster_file.with_suffix(\".txt\")))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79fb7da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-28T18:13:22.998061Z",
     "iopub.status.busy": "2023-10-28T18:13:22.997294Z",
     "iopub.status.idle": "2023-10-28T18:30:04.552880Z",
     "shell.execute_reply": "2023-10-28T18:30:04.551410Z"
    },
    "papermill": {
     "duration": 1001.564953,
     "end_time": "2023-10-28T18:30:04.555881",
     "exception": false,
     "start_time": "2023-10-28T18:13:22.990928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "Preparation (took 0.27s)\n",
      "Feat Eng (took 1.25s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 0 (took 0.02s)\n",
      "Preparation (took 1.61s)\n",
      "Feat Eng (took 1.37s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 10 (took 0.02s)\n",
      "Preparation (took 1.65s)\n",
      "Feat Eng (took 1.35s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 20 (took 0.02s)\n",
      "Preparation (took 1.73s)\n",
      "Feat Eng (took 1.46s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 30 (took 0.02s)\n",
      "Preparation (took 1.73s)\n",
      "Feat Eng (took 1.37s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 40 (took 0.02s)\n",
      "Preparation (took 1.71s)\n",
      "Feat Eng (took 1.40s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 50 (took 0.02s)\n",
      "Preparation (took 1.73s)\n",
      "Feat Eng (took 1.51s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 60 (took 0.02s)\n",
      "Preparation (took 1.78s)\n",
      "Feat Eng (took 1.44s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 70 (took 0.02s)\n",
      "Preparation (took 1.77s)\n",
      "Feat Eng (took 1.41s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 80 (took 0.02s)\n",
      "Preparation (took 1.79s)\n",
      "Feat Eng (took 1.55s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 90 (took 0.02s)\n",
      "Preparation (took 1.86s)\n",
      "Feat Eng (took 1.47s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 100 (took 0.02s)\n",
      "Preparation (took 1.87s)\n",
      "Feat Eng (took 1.60s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 110 (took 0.02s)\n",
      "Preparation (took 1.88s)\n",
      "Feat Eng (took 1.53s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 478, second in bucket 120 (took 0.03s)\n",
      "Preparation (took 1.92s)\n",
      "Feat Eng (took 1.49s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 130 (took 0.02s)\n",
      "Preparation (took 1.94s)\n",
      "Feat Eng (took 1.61s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 140 (took 0.02s)\n",
      "Preparation (took 1.96s)\n",
      "Feat Eng (took 1.50s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 150 (took 0.02s)\n",
      "Preparation (took 2.02s)\n",
      "Feat Eng (took 1.56s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 160 (took 0.02s)\n",
      "Preparation (took 2.01s)\n",
      "Feat Eng (took 1.65s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 170 (took 0.02s)\n",
      "Preparation (took 2.04s)\n",
      "Feat Eng (took 1.56s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 180 (took 0.02s)\n",
      "Preparation (took 2.06s)\n",
      "Feat Eng (took 1.61s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 190 (took 0.02s)\n",
      "Preparation (took 2.09s)\n",
      "Feat Eng (took 1.57s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 200 (took 0.02s)\n",
      "Preparation (took 2.23s)\n",
      "Feat Eng (took 1.96s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 210 (took 0.02s)\n",
      "Preparation (took 2.14s)\n",
      "Feat Eng (took 1.64s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 220 (took 0.02s)\n",
      "Preparation (took 2.16s)\n",
      "Feat Eng (took 1.59s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 478, second in bucket 230 (took 0.03s)\n",
      "Preparation (took 2.21s)\n",
      "Feat Eng (took 1.72s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 240 (took 0.02s)\n",
      "Preparation (took 2.21s)\n",
      "Feat Eng (took 1.62s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 250 (took 0.02s)\n",
      "Preparation (took 2.25s)\n",
      "Feat Eng (took 1.64s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 260 (took 0.02s)\n",
      "Preparation (took 2.26s)\n",
      "Feat Eng (took 1.69s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 270 (took 0.02s)\n",
      "Preparation (took 2.31s)\n",
      "Feat Eng (took 1.79s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 280 (took 0.02s)\n",
      "Preparation (took 2.43s)\n",
      "Feat Eng (took 1.72s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 290 (took 0.02s)\n",
      "Preparation (took 2.33s)\n",
      "Feat Eng (took 1.69s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 300 (took 0.02s)\n",
      "Preparation (took 2.38s)\n",
      "Feat Eng (took 1.82s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 310 (took 0.02s)\n",
      "Preparation (took 2.39s)\n",
      "Feat Eng (took 1.75s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 320 (took 0.02s)\n",
      "Preparation (took 2.41s)\n",
      "Feat Eng (took 1.80s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 330 (took 0.02s)\n",
      "Preparation (took 2.44s)\n",
      "Feat Eng (took 1.79s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 340 (took 0.02s)\n",
      "Preparation (took 2.45s)\n",
      "Feat Eng (took 1.89s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 350 (took 0.02s)\n",
      "Preparation (took 2.53s)\n",
      "Feat Eng (took 1.86s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 478, second in bucket 360 (took 0.03s)\n",
      "Preparation (took 2.51s)\n",
      "Feat Eng (took 1.94s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 370 (took 0.02s)\n",
      "Preparation (took 2.56s)\n",
      "Feat Eng (took 1.82s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 380 (took 0.02s)\n",
      "Preparation (took 2.57s)\n",
      "Feat Eng (took 1.82s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 390 (took 0.02s)\n",
      "Preparation (took 2.58s)\n",
      "Feat Eng (took 1.99s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 400 (took 0.02s)\n",
      "Preparation (took 2.60s)\n",
      "Feat Eng (took 1.88s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 410 (took 0.02s)\n",
      "Preparation (took 2.65s)\n",
      "Feat Eng (took 1.94s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 420 (took 0.02s)\n",
      "Preparation (took 2.68s)\n",
      "Feat Eng (took 2.10s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 430 (took 0.02s)\n",
      "Preparation (took 2.68s)\n",
      "Feat Eng (took 1.90s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 478, second in bucket 440 (took 0.03s)\n",
      "Preparation (took 2.70s)\n",
      "Feat Eng (took 1.93s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 450 (took 0.02s)\n",
      "Preparation (took 2.73s)\n",
      "Feat Eng (took 2.05s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 460 (took 0.02s)\n",
      "Preparation (took 2.77s)\n",
      "Feat Eng (took 1.95s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 470 (took 0.02s)\n",
      "Preparation (took 2.79s)\n",
      "Feat Eng (took 2.00s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 480 (took 0.02s)\n",
      "Preparation (took 2.82s)\n",
      "Feat Eng (took 2.13s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 490 (took 0.02s)\n",
      "Preparation (took 3.19s)\n",
      "Feat Eng (took 1.95s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 500 (took 0.02s)\n",
      "Preparation (took 2.85s)\n",
      "Feat Eng (took 2.00s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 510 (took 0.02s)\n",
      "Preparation (took 2.86s)\n",
      "Feat Eng (took 2.07s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 520 (took 0.02s)\n",
      "Preparation (took 2.92s)\n",
      "Feat Eng (took 2.01s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 530 (took 0.02s)\n",
      "Preparation (took 2.92s)\n",
      "Feat Eng (took 2.01s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 478, second in bucket 540 (took 0.02s)\n",
      "Preparation (took 2.99s)\n",
      "Feat Eng (took 2.20s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 0 (took 0.02s)\n",
      "Preparation (took 2.98s)\n",
      "Feat Eng (took 2.43s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 10 (took 0.02s)\n",
      "Preparation (took 3.02s)\n",
      "Feat Eng (took 2.05s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 20 (took 0.02s)\n",
      "Preparation (took 3.04s)\n",
      "Feat Eng (took 2.18s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 30 (took 0.02s)\n",
      "Preparation (took 3.05s)\n",
      "Feat Eng (took 2.09s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 40 (took 0.02s)\n",
      "Preparation (took 3.08s)\n",
      "Feat Eng (took 2.11s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 50 (took 0.02s)\n",
      "Preparation (took 3.08s)\n",
      "Feat Eng (took 2.21s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 60 (took 0.02s)\n",
      "Preparation (took 3.12s)\n",
      "Feat Eng (took 2.26s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 70 (took 0.02s)\n",
      "Preparation (took 3.15s)\n",
      "Feat Eng (took 2.12s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 80 (took 0.02s)\n",
      "Preparation (took 3.18s)\n",
      "Feat Eng (took 2.28s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 90 (took 0.02s)\n",
      "Preparation (took 3.18s)\n",
      "Feat Eng (took 2.16s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 100 (took 0.02s)\n",
      "Preparation (took 3.23s)\n",
      "Feat Eng (took 2.17s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 110 (took 0.02s)\n",
      "Preparation (took 3.23s)\n",
      "Feat Eng (took 2.28s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 120 (took 0.02s)\n",
      "Preparation (took 3.39s)\n",
      "Feat Eng (took 2.17s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 130 (took 0.02s)\n",
      "Preparation (took 3.27s)\n",
      "Feat Eng (took 2.19s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 140 (took 0.02s)\n",
      "Preparation (took 3.32s)\n",
      "Feat Eng (took 2.33s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 150 (took 0.02s)\n",
      "Preparation (took 3.32s)\n",
      "Feat Eng (took 2.25s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 160 (took 0.02s)\n",
      "Preparation (took 3.34s)\n",
      "Feat Eng (took 2.19s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 170 (took 0.02s)\n",
      "Preparation (took 3.37s)\n",
      "Feat Eng (took 2.32s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 180 (took 0.02s)\n",
      "Preparation (took 3.50s)\n",
      "Feat Eng (took 2.25s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 190 (took 0.02s)\n",
      "Preparation (took 3.43s)\n",
      "Feat Eng (took 2.29s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 200 (took 0.02s)\n",
      "Preparation (took 3.46s)\n",
      "Feat Eng (took 2.36s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 210 (took 0.02s)\n",
      "Preparation (took 3.52s)\n",
      "Feat Eng (took 2.28s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 220 (took 0.02s)\n",
      "Preparation (took 3.51s)\n",
      "Feat Eng (took 2.32s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 230 (took 0.02s)\n",
      "Preparation (took 3.76s)\n",
      "Feat Eng (took 2.30s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 240 (took 0.02s)\n",
      "Preparation (took 3.56s)\n",
      "Feat Eng (took 2.33s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 250 (took 0.02s)\n",
      "Preparation (took 3.58s)\n",
      "Feat Eng (took 2.45s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 260 (took 0.02s)\n",
      "Preparation (took 3.62s)\n",
      "Feat Eng (took 2.35s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 270 (took 0.02s)\n",
      "Preparation (took 3.60s)\n",
      "Feat Eng (took 2.38s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 280 (took 0.02s)\n",
      "Preparation (took 3.64s)\n",
      "Feat Eng (took 2.85s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 290 (took 0.02s)\n",
      "Preparation (took 3.72s)\n",
      "Feat Eng (took 2.42s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 300 (took 0.02s)\n",
      "Preparation (took 3.69s)\n",
      "Feat Eng (took 2.39s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 310 (took 0.02s)\n",
      "Preparation (took 3.75s)\n",
      "Feat Eng (took 2.53s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 320 (took 0.02s)\n",
      "Preparation (took 3.75s)\n",
      "Feat Eng (took 2.42s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 330 (took 0.02s)\n",
      "Preparation (took 3.78s)\n",
      "Feat Eng (took 2.52s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 340 (took 0.02s)\n",
      "Preparation (took 3.83s)\n",
      "Feat Eng (took 2.48s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 350 (took 0.02s)\n",
      "Preparation (took 3.84s)\n",
      "Feat Eng (took 2.58s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 360 (took 0.02s)\n",
      "Preparation (took 3.87s)\n",
      "Feat Eng (took 2.48s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 370 (took 0.02s)\n",
      "Preparation (took 3.86s)\n",
      "Feat Eng (took 2.49s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 380 (took 0.02s)\n",
      "Preparation (took 3.88s)\n",
      "Feat Eng (took 2.64s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 390 (took 0.02s)\n",
      "Preparation (took 3.93s)\n",
      "Feat Eng (took 2.47s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 400 (took 0.02s)\n",
      "Preparation (took 3.96s)\n",
      "Feat Eng (took 2.51s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 410 (took 0.02s)\n",
      "Preparation (took 3.98s)\n",
      "Feat Eng (took 2.63s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 420 (took 0.02s)\n",
      "Preparation (took 4.02s)\n",
      "Feat Eng (took 2.55s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 430 (took 0.02s)\n",
      "Preparation (took 4.15s)\n",
      "Feat Eng (took 2.55s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 440 (took 0.02s)\n",
      "Preparation (took 4.02s)\n",
      "Feat Eng (took 2.67s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 450 (took 0.02s)\n",
      "Preparation (took 4.09s)\n",
      "Feat Eng (took 2.58s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 460 (took 0.02s)\n",
      "Preparation (took 4.08s)\n",
      "Feat Eng (took 2.59s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 470 (took 0.02s)\n",
      "Preparation (took 4.12s)\n",
      "Feat Eng (took 2.74s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 480 (took 0.02s)\n",
      "Preparation (took 4.17s)\n",
      "Feat Eng (took 2.63s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 490 (took 0.02s)\n",
      "Preparation (took 4.18s)\n",
      "Feat Eng (took 2.66s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 500 (took 0.02s)\n",
      "Preparation (took 4.18s)\n",
      "Feat Eng (took 2.80s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 510 (took 0.02s)\n",
      "Preparation (took 4.25s)\n",
      "Feat Eng (took 2.62s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 520 (took 0.02s)\n",
      "Preparation (took 4.28s)\n",
      "Feat Eng (took 2.77s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 530 (took 0.02s)\n",
      "Preparation (took 4.28s)\n",
      "Feat Eng (took 2.80s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 479, second in bucket 540 (took 0.02s)\n",
      "Preparation (took 4.34s)\n",
      "Feat Eng (took 2.72s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 0 (took 0.02s)\n",
      "Preparation (took 4.32s)\n",
      "Feat Eng (took 2.68s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 10 (took 0.02s)\n",
      "Preparation (took 4.46s)\n",
      "Feat Eng (took 2.68s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 20 (took 0.02s)\n",
      "Preparation (took 4.44s)\n",
      "Feat Eng (took 2.74s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 30 (took 0.02s)\n",
      "Preparation (took 4.39s)\n",
      "Feat Eng (took 2.86s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 40 (took 0.02s)\n",
      "Preparation (took 4.45s)\n",
      "Feat Eng (took 2.77s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 50 (took 0.02s)\n",
      "Preparation (took 4.45s)\n",
      "Feat Eng (took 2.82s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 60 (took 0.02s)\n",
      "Preparation (took 4.58s)\n",
      "Feat Eng (took 2.87s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 70 (took 0.02s)\n",
      "Preparation (took 4.52s)\n",
      "Feat Eng (took 2.77s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 80 (took 0.02s)\n",
      "Preparation (took 4.57s)\n",
      "Feat Eng (took 2.75s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 90 (took 0.02s)\n",
      "Preparation (took 4.53s)\n",
      "Feat Eng (took 2.93s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 100 (took 0.02s)\n",
      "Preparation (took 4.63s)\n",
      "Feat Eng (took 3.00s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 110 (took 0.02s)\n",
      "Preparation (took 4.61s)\n",
      "Feat Eng (took 2.84s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 120 (took 0.02s)\n",
      "Preparation (took 4.62s)\n",
      "Feat Eng (took 2.97s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 130 (took 0.02s)\n",
      "Preparation (took 4.59s)\n",
      "Feat Eng (took 2.89s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 140 (took 0.02s)\n",
      "Preparation (took 4.63s)\n",
      "Feat Eng (took 3.27s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 150 (took 0.02s)\n",
      "Preparation (took 4.69s)\n",
      "Feat Eng (took 2.93s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 160 (took 0.02s)\n",
      "Preparation (took 4.71s)\n",
      "Feat Eng (took 2.87s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 170 (took 0.02s)\n",
      "Preparation (took 4.67s)\n",
      "Feat Eng (took 3.00s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 180 (took 0.02s)\n",
      "Preparation (took 4.75s)\n",
      "Feat Eng (took 3.20s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 190 (took 0.02s)\n",
      "Preparation (took 4.77s)\n",
      "Feat Eng (took 2.89s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 200 (took 0.02s)\n",
      "Preparation (took 4.83s)\n",
      "Feat Eng (took 3.05s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 210 (took 0.02s)\n",
      "Preparation (took 4.83s)\n",
      "Feat Eng (took 2.98s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 220 (took 0.02s)\n",
      "Preparation (took 4.83s)\n",
      "Feat Eng (took 3.05s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 230 (took 0.02s)\n",
      "Preparation (took 4.86s)\n",
      "Feat Eng (took 2.99s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 480, second in bucket 240 (took 0.03s)\n",
      "Preparation (took 4.89s)\n",
      "Feat Eng (took 3.06s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 250 (took 0.02s)\n",
      "Preparation (took 4.98s)\n",
      "Feat Eng (took 3.01s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 260 (took 0.02s)\n",
      "Preparation (took 4.96s)\n",
      "Feat Eng (took 3.30s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 270 (took 0.02s)\n",
      "Preparation (took 4.98s)\n",
      "Feat Eng (took 3.03s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 280 (took 0.02s)\n",
      "Preparation (took 5.00s)\n",
      "Feat Eng (took 3.07s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 290 (took 0.02s)\n",
      "Preparation (took 5.02s)\n",
      "Feat Eng (took 3.01s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 300 (took 0.02s)\n",
      "Preparation (took 5.10s)\n",
      "Feat Eng (took 3.24s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 310 (took 0.02s)\n",
      "Preparation (took 5.10s)\n",
      "Feat Eng (took 3.08s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 320 (took 0.02s)\n",
      "Preparation (took 5.10s)\n",
      "Feat Eng (took 3.21s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 330 (took 0.02s)\n",
      "Preparation (took 5.13s)\n",
      "Feat Eng (took 3.16s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 340 (took 0.02s)\n",
      "Preparation (took 5.26s)\n",
      "Feat Eng (took 3.12s)\n",
      "Inference (took 0.03s)\n",
      "Date ID 480, second in bucket 350 (took 0.03s)\n",
      "Preparation (took 5.18s)\n",
      "Feat Eng (took 3.26s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 360 (took 0.02s)\n",
      "Preparation (took 5.24s)\n",
      "Feat Eng (took 3.15s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 370 (took 0.02s)\n",
      "Preparation (took 5.24s)\n",
      "Feat Eng (took 3.19s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 380 (took 0.02s)\n",
      "Preparation (took 5.43s)\n",
      "Feat Eng (took 3.25s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 390 (took 0.02s)\n",
      "Preparation (took 5.32s)\n",
      "Feat Eng (took 3.20s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 400 (took 0.02s)\n",
      "Preparation (took 5.33s)\n",
      "Feat Eng (took 3.23s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 410 (took 0.02s)\n",
      "Preparation (took 5.33s)\n",
      "Feat Eng (took 3.43s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 420 (took 0.02s)\n",
      "Preparation (took 5.40s)\n",
      "Feat Eng (took 3.22s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 430 (took 0.02s)\n",
      "Preparation (took 5.39s)\n",
      "Feat Eng (took 3.23s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 440 (took 0.02s)\n",
      "Preparation (took 5.42s)\n",
      "Feat Eng (took 3.37s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 450 (took 0.02s)\n",
      "Preparation (took 5.47s)\n",
      "Feat Eng (took 3.30s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 460 (took 0.02s)\n",
      "Preparation (took 5.45s)\n",
      "Feat Eng (took 3.39s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 470 (took 0.02s)\n",
      "Preparation (took 5.47s)\n",
      "Feat Eng (took 3.26s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 480 (took 0.02s)\n",
      "Preparation (took 5.45s)\n",
      "Feat Eng (took 3.33s)\n",
      "Inference (took 0.04s)\n",
      "Date ID 480, second in bucket 490 (took 0.04s)\n",
      "Preparation (took 5.58s)\n",
      "Feat Eng (took 3.45s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 500 (took 0.02s)\n",
      "Preparation (took 5.54s)\n",
      "Feat Eng (took 3.34s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 510 (took 0.02s)\n",
      "Preparation (took 5.60s)\n",
      "Feat Eng (took 3.28s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 520 (took 0.02s)\n",
      "Preparation (took 5.61s)\n",
      "Feat Eng (took 3.41s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 530 (took 0.02s)\n",
      "Preparation (took 5.66s)\n",
      "Feat Eng (took 3.33s)\n",
      "Inference (took 0.02s)\n",
      "Date ID 480, second in bucket 540 (took 0.02s)\n"
     ]
    }
   ],
   "source": [
    "from utils.files import read_json\n",
    "from utils.features import make_features, select_features, make_rolling_features\n",
    "from utils.aggregations import aggregate\n",
    "from lightgbm import Booster\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "features = read_json(CFG.FEATURES_PATH.joinpath(CFG.FEATURES_NAME))\n",
    "selected_features = features[\"selected_features\"]\n",
    "selected_features.remove(\"target\") # In case it has been included\n",
    "stock_weights = features[\"stock_weights\"]\n",
    "counter = 0\n",
    "predictions = []\n",
    "\n",
    "models_boosters = CFG.MODEL_PATH.glob(\"**/*.txt\")\n",
    "models = [load_model(Booster, path) for path in models_boosters][:1]\n",
    "\n",
    "feat_prev = None\n",
    "previous_targets = []\n",
    "cummulative_feat = None\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    #################################################\n",
    "    # Accumulate data\n",
    "    #################################################\n",
    "    revealed_feat = revealed_targets.copy()\n",
    "    current_date_id = test[\"date_id\"].iloc[0]\n",
    "    current_second_in_bucket = test[\"seconds_in_bucket\"].iloc[0]\n",
    "\n",
    "    # Accumulate features over time for rolling features\n",
    "    cummulative_feat = test if cummulative_feat is None else \\\n",
    "            pd.concat([cummulative_feat, test], ignore_index=True, axis=0)\n",
    "\n",
    "    # Drop features with certain age (this maintains the memory usage stable)\n",
    "    cummulative_feat = cummulative_feat[cummulative_feat[\"date_id\"] > \\\n",
    "                                        (current_date_id - CFG.MEMORY_HORIZON)]\n",
    "\n",
    "    # Add previous targets to the rolling cummulative features\n",
    "    if revealed_feat.shape[0] > 1:\n",
    "        revealed_feat = revealed_feat[[\"stock_id\", \"revealed_date_id\", \"seconds_in_bucket\", \"revealed_target\"]]\n",
    "        revealed_feat = revealed_feat.rename(columns={\"revealed_target\": \"target\", \"revealed_date_id\": \"date_id\"})\n",
    "        cummulative_feat = pd.merge(revealed_feat, cummulative_feat, on=[\"stock_id\", \"date_id\", \"seconds_in_bucket\"], how=\"outer\")\n",
    "\n",
    "    for col in cummulative_feat.columns:\n",
    "        cummulative_feat[col] = cummulative_feat[col].apply(lambda x: x if not pd.isna(x) else np.nan)\n",
    "\n",
    "    elapsed = timer() - start\n",
    "    print(f\"Preparation (took {elapsed:.2f}s)\")\n",
    "\n",
    "    #################################################\n",
    "    # Feature engineering\n",
    "    #################################################\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Create new features\n",
    "    cummulative_feat = make_features(cummulative_feat, reduce_memory=True)\n",
    "\n",
    "    # Apply (stock-wise) aggregations\n",
    "    _, aggregations = aggregate(cummulative_feat, weights=stock_weights)\n",
    "    cummulative_feat = apply_aggregations(cummulative_feat, aggregations_date=aggregations, reduce_memory=True)\n",
    "\n",
    "    # Get rolling features\n",
    "    cummulative_feat = make_rolling_features(cummulative_feat, reduce_memory=True)\n",
    "\n",
    "    # Get only the features from the current date and second\n",
    "    feat = (cummulative_feat[(cummulative_feat[\"date_id\"] == current_date_id) & \\\n",
    "                             (cummulative_feat[\"seconds_in_bucket\"] == current_second_in_bucket)]).copy().reset_index()\n",
    "\n",
    "    # Perform feature selection for inference. This also ensures the order is the same than during training\n",
    "    feat = select_features(feat, selected_features, reduce_memory=True) \n",
    "\n",
    "    elapsed = timer() - start\n",
    "    print(f\"Feat Eng (took {elapsed:.2f}s)\")\n",
    "    \n",
    "    start = timer()\n",
    "    #################################################\n",
    "    # Prediction\n",
    "    #################################################\n",
    "    # Mean ensemble\n",
    "    prediction = 0\n",
    "    for model in models:\n",
    "        prediction += model.predict(feat)   \n",
    "    prediction /= len(models)\n",
    "\n",
    "    prediction = zero_sum(prediction, test.loc[:, \"bid_size\"] + test.loc[:, \"ask_size\"])\n",
    "    elapsed = timer() - start\n",
    "    print(f\"Inference (took {elapsed:.2f}s)\")\n",
    "\n",
    "    #################################################\n",
    "    # Storage\n",
    "    #################################################\n",
    "    sample_prediction[\"target\"] = prediction\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n",
    "\n",
    "    elapsed = timer() - start\n",
    "    print(f\"Date ID {current_date_id}, second in bucket {current_second_in_bucket} (took {elapsed:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21bc14",
   "metadata": {
    "papermill": {
     "duration": 0.034156,
     "end_time": "2023-10-28T18:30:04.625319",
     "exception": false,
     "start_time": "2023-10-28T18:30:04.591163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1006.721721,
   "end_time": "2023-10-28T18:30:05.384289",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-28T18:13:18.662568",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
