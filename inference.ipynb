{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6675a9ce",
   "metadata": {
    "papermill": {
     "duration": 0.003312,
     "end_time": "2023-10-15T16:08:05.286505",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.283193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trading at the Close - Inference\n",
    "-----------------------\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322aff9",
   "metadata": {
    "papermill": {
     "duration": 0.002489,
     "end_time": "2023-10-15T16:08:05.293598",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.291109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a690d768",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.300923Z",
     "iopub.status.busy": "2023-10-15T16:08:05.300510Z",
     "iopub.status.idle": "2023-10-15T16:08:05.685263Z",
     "shell.execute_reply": "2023-10-15T16:08:05.684125Z"
    },
    "papermill": {
     "duration": 0.391445,
     "end_time": "2023-10-15T16:08:05.687732",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.296287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef98ce2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.695112Z",
     "iopub.status.busy": "2023-10-15T16:08:05.694610Z",
     "iopub.status.idle": "2023-10-15T16:08:05.701183Z",
     "shell.execute_reply": "2023-10-15T16:08:05.699870Z"
    },
    "papermill": {
     "duration": 0.013523,
     "end_time": "2023-10-15T16:08:05.704159",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.690636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\kaggle\\\\input\\\\optiver-inference-utils', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close', 'C:\\\\Program Files\\\\Python\\\\python310.zip', 'C:\\\\Program Files\\\\Python\\\\DLLs', 'C:\\\\Program Files\\\\Python\\\\lib', 'C:\\\\Program Files\\\\Python', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close\\\\.venv', '', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close\\\\.venv\\\\lib\\\\site-packages', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close\\\\.venv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close\\\\.venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\salva\\\\Documents\\\\Python Projects\\\\trading-at-the-close\\\\.venv\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "utils_path = Path(\"/\", \"kaggle\", \"input\", \"optiver-inference-utils\")\n",
    "if str(utils_path) not in sys.path:\n",
    "    sys.path = [str(utils_path),] + sys.path\n",
    "    \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcfe055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.711107Z",
     "iopub.status.busy": "2023-10-15T16:08:05.710781Z",
     "iopub.status.idle": "2023-10-15T16:08:05.716012Z",
     "shell.execute_reply": "2023-10-15T16:08:05.714923Z"
    },
    "papermill": {
     "duration": 0.011112,
     "end_time": "2023-10-15T16:08:05.718081",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.706969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    LOCAL = True\n",
    "    JOBS_PATH_LOCAL = Path(\".\", \"job_artifacts\")\n",
    "    JOBS_PATH_ONLINE = Path(\"/\", \"kaggle\", \"input\", \"optiver-trained-artifacts\", \"job_artifacts\")\n",
    "    TEST_PATH = Path(\".\", \"train_files\", \"train.csv\")\n",
    "    INPUT_METADATA_CASE = \"optiver-feature_selection-0010\"\n",
    "    INPUT_METADATA_NAME = \"output_metadata.json\"\n",
    "    MODEL_CASE = \"optiver-feature_selection-0010\"\n",
    "    CACHE_HORIZON = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf842d",
   "metadata": {
    "papermill": {
     "duration": 0.002372,
     "end_time": "2023-10-15T16:08:05.723299",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.720927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4774a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.730096Z",
     "iopub.status.busy": "2023-10-15T16:08:05.729713Z",
     "iopub.status.idle": "2023-10-15T16:08:05.734994Z",
     "shell.execute_reply": "2023-10-15T16:08:05.733846Z"
    },
    "papermill": {
     "duration": 0.011263,
     "end_time": "2023-10-15T16:08:05.737129",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.725866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean(prices):\n",
    "    prices -= prices.mean()\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc48e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.780569Z",
     "iopub.status.busy": "2023-10-15T16:08:05.780186Z",
     "iopub.status.idle": "2023-10-15T16:08:05.785998Z",
     "shell.execute_reply": "2023-10-15T16:08:05.784973Z"
    },
    "papermill": {
     "duration": 0.011937,
     "end_time": "2023-10-15T16:08:05.788117",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.776180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    model_type,\n",
    "    booster_file\n",
    "):\n",
    "    model = model_type(model_file=str(booster_file.with_suffix(\".txt\")))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mock API...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\inference.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salva/Documents/Python%20Projects/trading-at-the-close/inference.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salva/Documents/Python%20Projects/trading-at-the-close/inference.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(CFG\u001b[39m.\u001b[39mTEST_PATH)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/salva/Documents/Python%20Projects/trading-at-the-close/inference.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m env \u001b[39m=\u001b[39m MockApi(df, start_date\u001b[39m=\u001b[39;49m\u001b[39m478\u001b[39;49m, end_date\u001b[39m=\u001b[39;49m\u001b[39m480\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salva/Documents/Python%20Projects/trading-at-the-close/inference.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m iter_test \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39miter_test()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salva/Documents/Python%20Projects/trading-at-the-close/inference.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m CFG\u001b[39m.\u001b[39mJOBS_PATH \u001b[39m=\u001b[39m CFG\u001b[39m.\u001b[39mJOBS_PATH_LOCAL\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\utils\\public_timeseries_testing_util.py:36\u001b[0m, in \u001b[0;36mMockApi.__init__\u001b[1;34m(self, train, start_date, end_date, submission_path)\u001b[0m\n\u001b[0;32m     34\u001b[0m revealed[\u001b[39m\"\u001b[39m\u001b[39mrevealed_date_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m revealed[\u001b[39m\"\u001b[39m\u001b[39mdate_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     35\u001b[0m revealed[\u001b[39m\"\u001b[39m\u001b[39mrevealed_time_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m revealed[\u001b[39m\"\u001b[39m\u001b[39mtime_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m55\u001b[39m\n\u001b[1;32m---> 36\u001b[0m revealed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(\n\u001b[0;32m     37\u001b[0m     revealed,\n\u001b[0;32m     38\u001b[0m     train[[\u001b[39m\"\u001b[39;49m\u001b[39mstock_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdate_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtime_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m]],\n\u001b[0;32m     39\u001b[0m     how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     40\u001b[0m     left_on\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mstock_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrevealed_date_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrevealed_time_id\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     41\u001b[0m     right_on\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mstock_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdate_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtime_id\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     43\u001b[0m revealed\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdate_id_y\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtime_id_y\u001b[39m\u001b[39m\"\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m revealed\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdate_id_x\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdate_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtime_id_x\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtime_id\u001b[39m\u001b[39m\"\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:883\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[0;32m    881\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m--> 883\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[0;32m    885\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1133\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1130\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[0;32m   1131\u001b[0m     )\n\u001b[0;32m   1132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[0;32m   1135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1105\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[0;32m   1104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[0;32m   1106\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[0;32m   1107\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1713\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1707\u001b[0m lkey, rkey \u001b[39m=\u001b[39m _get_join_keys(llab, rlab, \u001b[39mtuple\u001b[39m(shape), sort)\n\u001b[0;32m   1709\u001b[0m \u001b[39m# factorize keys to a dense i8 space\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# `count` is the num. of unique keys\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# set(lkey) | set(rkey) == range(count)\u001b[39;00m\n\u001b[1;32m-> 1713\u001b[0m lkey, rkey, count \u001b[39m=\u001b[39m _factorize_keys(lkey, rkey, sort\u001b[39m=\u001b[39;49msort, how\u001b[39m=\u001b[39;49mhow)\n\u001b[0;32m   1714\u001b[0m \u001b[39m# preserve left frame order if how == 'left' and sort == False\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\salva\\Documents\\Python Projects\\trading-at-the-close\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2494\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[1;34m(lk, rk, sort, how)\u001b[0m\n\u001b[0;32m   2489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2490\u001b[0m     \u001b[39m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   2491\u001b[0m     \u001b[39m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[39;00m\n\u001b[0;32m   2492\u001b[0m     \u001b[39m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m     llab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39mfactorize(lk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 2494\u001b[0m     rlab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39;49mfactorize(rk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2495\u001b[0m \u001b[39massert\u001b[39;00m llab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), llab\u001b[39m.\u001b[39mdtype\n\u001b[0;32m   2496\u001b[0m \u001b[39massert\u001b[39;00m rlab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), rlab\u001b[39m.\u001b[39mdtype\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Online API\n",
    "if not CFG.LOCAL:\n",
    "\n",
    "    import optiver2023\n",
    "    optiver2023.make_env.func_dict['__called__'] = False # This enables running the API again if an error was produced\n",
    "\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "\n",
    "    CFG.JOBS_PATH = CFG.JOBS_PATH_ONLINE\n",
    "\n",
    "# Local API\n",
    "else:\n",
    "    from utils.public_timeseries_testing_util import MockApi\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(CFG.TEST_PATH)\n",
    "    env = MockApi(df, start_date=478, end_date=480)\n",
    "    iter_test = env.iter_test()\n",
    "\n",
    "    CFG.JOBS_PATH = CFG.JOBS_PATH_LOCAL\n",
    "\n",
    "CFG.INPUT_METADATA_PATH = CFG.JOBS_PATH.joinpath(CFG.INPUT_METADATA_CASE, CFG.INPUT_METADATA_NAME)\n",
    "CFG.MODEL_PATH = CFG.JOBS_PATH.joinpath(CFG.MODEL_CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from loguru import logger\n",
    "    import sys\n",
    "    logger.remove()\n",
    "    logger.add(sys.stdout, level=\"ERROR\")\n",
    "except:\n",
    "    import logging\n",
    "    logger = logging.getLogger(\"__main__\")\n",
    "    logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ac5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:08:05.795554Z",
     "iopub.status.busy": "2023-10-15T16:08:05.795184Z",
     "iopub.status.idle": "2023-10-15T16:08:53.052733Z",
     "shell.execute_reply": "2023-10-15T16:08:53.051619Z"
    },
    "papermill": {
     "duration": 47.264671,
     "end_time": "2023-10-15T16:08:53.055745",
     "exception": false,
     "start_time": "2023-10-15T16:08:05.791074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date ID 478, second in bucket 0 (took 0.91s)\n",
      "Date ID 478, second in bucket 10 (took 0.93s)\n",
      "Date ID 478, second in bucket 20 (took 0.98s)\n",
      "Date ID 478, second in bucket 30 (took 1.07s)\n",
      "Date ID 478, second in bucket 40 (took 1.14s)\n",
      "Date ID 478, second in bucket 50 (took 1.25s)\n",
      "Date ID 478, second in bucket 60 (took 1.46s)\n",
      "Date ID 478, second in bucket 70 (took 1.40s)\n",
      "Date ID 478, second in bucket 80 (took 1.53s)\n",
      "Date ID 478, second in bucket 90 (took 1.57s)\n",
      "Date ID 478, second in bucket 100 (took 1.61s)\n",
      "Date ID 478, second in bucket 110 (took 1.63s)\n",
      "Date ID 478, second in bucket 120 (took 1.60s)\n",
      "Date ID 478, second in bucket 130 (took 1.59s)\n",
      "Date ID 478, second in bucket 140 (took 1.62s)\n",
      "Date ID 478, second in bucket 150 (took 1.62s)\n",
      "Date ID 478, second in bucket 160 (took 1.62s)\n",
      "Date ID 478, second in bucket 170 (took 1.60s)\n",
      "Date ID 478, second in bucket 180 (took 1.61s)\n",
      "Date ID 478, second in bucket 190 (took 1.60s)\n",
      "Date ID 478, second in bucket 200 (took 1.60s)\n",
      "Date ID 478, second in bucket 210 (took 1.74s)\n",
      "Date ID 478, second in bucket 220 (took 1.62s)\n",
      "Date ID 478, second in bucket 230 (took 1.61s)\n",
      "Date ID 478, second in bucket 240 (took 1.66s)\n",
      "Date ID 478, second in bucket 250 (took 1.60s)\n",
      "Date ID 478, second in bucket 260 (took 1.62s)\n",
      "Date ID 478, second in bucket 270 (took 1.68s)\n",
      "Date ID 478, second in bucket 280 (took 1.63s)\n",
      "Date ID 478, second in bucket 290 (took 1.60s)\n",
      "Date ID 478, second in bucket 300 (took 1.61s)\n",
      "Date ID 478, second in bucket 310 (took 1.62s)\n",
      "Date ID 478, second in bucket 320 (took 1.63s)\n",
      "Date ID 478, second in bucket 330 (took 1.62s)\n",
      "Date ID 478, second in bucket 340 (took 1.62s)\n",
      "Date ID 478, second in bucket 350 (took 1.74s)\n",
      "Date ID 478, second in bucket 360 (took 1.60s)\n",
      "Date ID 478, second in bucket 370 (took 1.62s)\n",
      "Date ID 478, second in bucket 380 (took 1.61s)\n",
      "Date ID 478, second in bucket 390 (took 1.62s)\n",
      "Date ID 478, second in bucket 400 (took 1.65s)\n",
      "Date ID 478, second in bucket 410 (took 1.62s)\n",
      "Date ID 478, second in bucket 420 (took 1.63s)\n",
      "Date ID 478, second in bucket 430 (took 1.64s)\n",
      "Date ID 478, second in bucket 440 (took 1.61s)\n",
      "Date ID 478, second in bucket 450 (took 1.64s)\n",
      "Date ID 478, second in bucket 460 (took 1.70s)\n",
      "Date ID 478, second in bucket 470 (took 1.63s)\n",
      "Date ID 478, second in bucket 480 (took 1.63s)\n",
      "Date ID 478, second in bucket 490 (took 1.79s)\n",
      "Date ID 478, second in bucket 500 (took 1.63s)\n",
      "Date ID 478, second in bucket 510 (took 1.63s)\n",
      "Date ID 478, second in bucket 520 (took 1.65s)\n",
      "Date ID 478, second in bucket 530 (took 1.62s)\n",
      "Date ID 478, second in bucket 540 (took 1.62s)\n",
      "Date ID 479, second in bucket 0 (took 1.73s)\n",
      "Date ID 479, second in bucket 10 (took 1.70s)\n",
      "Date ID 479, second in bucket 20 (took 1.69s)\n",
      "Date ID 479, second in bucket 30 (took 1.71s)\n",
      "Date ID 479, second in bucket 40 (took 1.72s)\n",
      "Date ID 479, second in bucket 50 (took 1.72s)\n",
      "Date ID 479, second in bucket 60 (took 1.70s)\n",
      "Date ID 479, second in bucket 70 (took 1.74s)\n",
      "Date ID 479, second in bucket 80 (took 1.84s)\n",
      "Date ID 479, second in bucket 90 (took 1.70s)\n",
      "Date ID 479, second in bucket 100 (took 1.62s)\n",
      "Date ID 479, second in bucket 110 (took 1.61s)\n",
      "Date ID 479, second in bucket 120 (took 1.61s)\n",
      "Date ID 479, second in bucket 130 (took 1.59s)\n",
      "Date ID 479, second in bucket 140 (took 1.60s)\n",
      "Date ID 479, second in bucket 150 (took 1.60s)\n",
      "Date ID 479, second in bucket 160 (took 1.63s)\n",
      "Date ID 479, second in bucket 170 (took 1.60s)\n",
      "Date ID 479, second in bucket 180 (took 1.61s)\n",
      "Date ID 479, second in bucket 190 (took 1.66s)\n",
      "Date ID 479, second in bucket 200 (took 1.60s)\n",
      "Date ID 479, second in bucket 210 (took 1.58s)\n",
      "Date ID 479, second in bucket 220 (took 1.62s)\n",
      "Date ID 479, second in bucket 230 (took 1.72s)\n",
      "Date ID 479, second in bucket 240 (took 1.60s)\n",
      "Date ID 479, second in bucket 250 (took 1.67s)\n",
      "Date ID 479, second in bucket 260 (took 1.60s)\n",
      "Date ID 479, second in bucket 270 (took 1.62s)\n",
      "Date ID 479, second in bucket 280 (took 1.60s)\n",
      "Date ID 479, second in bucket 290 (took 1.61s)\n",
      "Date ID 479, second in bucket 300 (took 1.61s)\n",
      "Date ID 479, second in bucket 310 (took 1.62s)\n",
      "Date ID 479, second in bucket 320 (took 1.62s)\n",
      "Date ID 479, second in bucket 330 (took 1.65s)\n",
      "Date ID 479, second in bucket 340 (took 1.64s)\n",
      "Date ID 479, second in bucket 350 (took 1.63s)\n",
      "Date ID 479, second in bucket 360 (took 1.61s)\n",
      "Date ID 479, second in bucket 370 (took 1.76s)\n",
      "Date ID 479, second in bucket 380 (took 1.62s)\n",
      "Date ID 479, second in bucket 390 (took 1.60s)\n",
      "Date ID 479, second in bucket 400 (took 1.62s)\n",
      "Date ID 479, second in bucket 410 (took 1.65s)\n",
      "Date ID 479, second in bucket 420 (took 1.63s)\n",
      "Date ID 479, second in bucket 430 (took 1.63s)\n",
      "Date ID 479, second in bucket 440 (took 1.65s)\n",
      "Date ID 479, second in bucket 450 (took 1.63s)\n",
      "Date ID 479, second in bucket 460 (took 1.63s)\n",
      "Date ID 479, second in bucket 470 (took 1.66s)\n",
      "Date ID 479, second in bucket 480 (took 1.65s)\n",
      "Date ID 479, second in bucket 490 (took 1.64s)\n",
      "Date ID 479, second in bucket 500 (took 1.61s)\n",
      "Date ID 479, second in bucket 510 (took 1.76s)\n",
      "Date ID 479, second in bucket 520 (took 1.62s)\n",
      "Date ID 479, second in bucket 530 (took 1.64s)\n",
      "Date ID 479, second in bucket 540 (took 1.63s)\n",
      "Date ID 480, second in bucket 0 (took 1.73s)\n",
      "Date ID 480, second in bucket 10 (took 1.70s)\n",
      "Date ID 480, second in bucket 20 (took 1.71s)\n",
      "Date ID 480, second in bucket 30 (took 1.72s)\n",
      "Date ID 480, second in bucket 40 (took 1.70s)\n",
      "Date ID 480, second in bucket 50 (took 1.72s)\n",
      "Date ID 480, second in bucket 60 (took 1.70s)\n",
      "Date ID 480, second in bucket 70 (took 1.74s)\n",
      "Date ID 480, second in bucket 80 (took 1.73s)\n",
      "Date ID 480, second in bucket 90 (took 1.81s)\n",
      "Date ID 480, second in bucket 100 (took 1.60s)\n",
      "Date ID 480, second in bucket 110 (took 1.76s)\n",
      "Date ID 480, second in bucket 120 (took 1.61s)\n",
      "Date ID 480, second in bucket 130 (took 1.62s)\n",
      "Date ID 480, second in bucket 140 (took 1.63s)\n",
      "Date ID 480, second in bucket 150 (took 1.65s)\n",
      "Date ID 480, second in bucket 160 (took 1.62s)\n",
      "Date ID 480, second in bucket 170 (took 1.61s)\n",
      "Date ID 480, second in bucket 180 (took 1.62s)\n",
      "Date ID 480, second in bucket 190 (took 1.65s)\n",
      "Date ID 480, second in bucket 200 (took 1.64s)\n",
      "Date ID 480, second in bucket 210 (took 1.59s)\n",
      "Date ID 480, second in bucket 220 (took 1.57s)\n",
      "Date ID 480, second in bucket 230 (took 1.65s)\n",
      "Date ID 480, second in bucket 240 (took 1.62s)\n",
      "Date ID 480, second in bucket 250 (took 1.77s)\n",
      "Date ID 480, second in bucket 260 (took 1.64s)\n",
      "Date ID 480, second in bucket 270 (took 1.61s)\n",
      "Date ID 480, second in bucket 280 (took 1.61s)\n",
      "Date ID 480, second in bucket 290 (took 1.67s)\n",
      "Date ID 480, second in bucket 300 (took 1.61s)\n",
      "Date ID 480, second in bucket 310 (took 1.60s)\n",
      "Date ID 480, second in bucket 320 (took 1.62s)\n",
      "Date ID 480, second in bucket 330 (took 1.64s)\n",
      "Date ID 480, second in bucket 340 (took 1.59s)\n",
      "Date ID 480, second in bucket 350 (took 1.60s)\n",
      "Date ID 480, second in bucket 360 (took 1.60s)\n",
      "Date ID 480, second in bucket 370 (took 1.61s)\n",
      "Date ID 480, second in bucket 380 (took 1.61s)\n",
      "Date ID 480, second in bucket 390 (took 1.64s)\n",
      "Date ID 480, second in bucket 400 (took 1.76s)\n",
      "Date ID 480, second in bucket 410 (took 1.65s)\n",
      "Date ID 480, second in bucket 420 (took 1.63s)\n",
      "Date ID 480, second in bucket 430 (took 1.70s)\n",
      "Date ID 480, second in bucket 440 (took 1.68s)\n",
      "Date ID 480, second in bucket 450 (took 1.69s)\n",
      "Date ID 480, second in bucket 460 (took 1.70s)\n",
      "Date ID 480, second in bucket 470 (took 1.73s)\n",
      "Date ID 480, second in bucket 480 (took 1.74s)\n",
      "Date ID 480, second in bucket 490 (took 1.62s)\n",
      "Date ID 480, second in bucket 500 (took 1.60s)\n",
      "Date ID 480, second in bucket 510 (took 1.65s)\n",
      "Date ID 480, second in bucket 520 (took 1.56s)\n",
      "Date ID 480, second in bucket 530 (took 1.58s)\n",
      "Date ID 480, second in bucket 540 (took 1.71s)\n"
     ]
    }
   ],
   "source": [
    "from utils.files import read_json\n",
    "from utils.features import feature_engineering, select_features\n",
    "from lightgbm import Booster\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "metadata = read_json(CFG.INPUT_METADATA_PATH)\n",
    "stock_weights = {int(k): v for k, v in metadata[\"stock_weights\"].items()}\n",
    "stock_clusters = {int(k): v for k, v in metadata[\"stock_clusters\"].items()}\n",
    "selected_features = metadata[\"selected_features\"]\n",
    "\n",
    "counter = 0\n",
    "predictions, qps = [], []\n",
    "\n",
    "models_boosters = CFG.MODEL_PATH.glob(\"**/*.txt\")\n",
    "models = [load_model(Booster, path) for path in models_boosters]\n",
    "\n",
    "cache_test = pd.DataFrame()\n",
    "cache_revealed_targets = None\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    start = timer()\n",
    "\n",
    "    current_date_id = test[\"date_id\"].iloc[0]\n",
    "    current_second_in_bucket = test[\"seconds_in_bucket\"].iloc[0]\n",
    "\n",
    "    # Save revealed target when available\n",
    "    if revealed_targets.shape[0] > 1:\n",
    "        cache_revealed_targets = revealed_targets\n",
    "\n",
    "    # Cache inference data (without feature engineering for memory reasons)\n",
    "    cache_test = pd.concat([cache_test, test], ignore_index=True, axis=0)\n",
    "    if counter > 0:\n",
    "        cache_test = cache_test.groupby([\"stock_id\"]).tail(CFG.CACHE_HORIZON).sort_values(\n",
    "                by=[\"date_id\", \"seconds_in_bucket\", \"stock_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # Do feature engineering over cache and take only the data relevant for inference in this timestep (revealed target is introduced by other means)\n",
    "    feat = feature_engineering(cache_test, revealed_target=False, weights=stock_weights, clusters=stock_clusters)[-test.shape[0]:]\n",
    "    #if cache_revealed_targets is not None:\n",
    "    #    feat[\"revealed_target\"] = cache_revealed_targets[\"revealed_target\"].loc[\n",
    "    #        (cache_revealed_targets[\"revealed_date_id\"] == current_date_id - 1) & (cache_revealed_targets[\"seconds_in_bucket\"] == current_second_in_bucket)]\n",
    "    #else:\n",
    "    #    feat[\"revealed_target\"] = np.nan\n",
    "\n",
    "    # New addition to the inference APU\n",
    "    if feat.currently_scored.iloc[0] == False:\n",
    "        sample_prediction[\"target\"] = 0\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1\n",
    "        qps.append(timer() - start)\n",
    "        if counter % 10 == 0:\n",
    "            print(counter, \"qps:\", np.mean(qps))\n",
    "        continue\n",
    "\n",
    "    feat = select_features(feat, selected_features, reduce_memory=False)\n",
    "    # Perform prediction as a mean ensemble\n",
    "    prediction = 0\n",
    "    for model in models:\n",
    "        prediction += model.predict(feat)   \n",
    "    prediction /= len(models)\n",
    "\n",
    "    # Do postprocessing over the redictions\n",
    "    #prediction = zero_sum(prediction, test[\"bid_size\"] + test[\"ask_size\"])\n",
    "    prediction = zero_mean(prediction)\n",
    "    end = timer()\n",
    "\n",
    "    # Save prediction\n",
    "    sample_prediction[\"target\"] = prediction\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n",
    "\n",
    "    qps.append(timer() - start)\n",
    "\n",
    "    if counter % 10 == 0:\n",
    "        print(f\"Date ID {current_date_id}, second in bucket {current_second_in_bucket} qps: {np.mean(qps)}\")\n",
    "\n",
    "    time_cost = 1.146 * np.mean(qps)\n",
    "    print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.832865,
   "end_time": "2023-10-15T16:08:53.787762",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-15T16:08:01.954897",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
